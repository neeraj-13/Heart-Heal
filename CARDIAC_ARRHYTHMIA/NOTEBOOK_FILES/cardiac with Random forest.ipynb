{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    ##data handling\n",
    "import numpy          ##numerical python  in mathematical calc\n",
    "from sklearn import svm      ## proving us regarding algorithm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_arrhythmia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>qrs_duration</th>\n",
       "      <th>p-r_interval</th>\n",
       "      <th>q-t_interval</th>\n",
       "      <th>t_interval</th>\n",
       "      <th>p_interval</th>\n",
       "      <th>qrs</th>\n",
       "      <th>...</th>\n",
       "      <th>KY</th>\n",
       "      <th>KZ</th>\n",
       "      <th>LA</th>\n",
       "      <th>LB</th>\n",
       "      <th>LC</th>\n",
       "      <th>LD</th>\n",
       "      <th>LE</th>\n",
       "      <th>LF</th>\n",
       "      <th>LG</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Height  Weight  qrs_duration  p-r_interval  q-t_interval  \\\n",
       "0   75    0     190      80            91           193           371   \n",
       "1   56    1     165      64            81           174           401   \n",
       "2   54    0     172      95           138           163           386   \n",
       "3   55    0     175      94           100           202           380   \n",
       "4   75    0     190      80            88           181           360   \n",
       "\n",
       "   t_interval  p_interval  qrs  ...   KY    KZ   LA   LB  LC   LD   LE    LF  \\\n",
       "0         174         121  -16  ...  0.0   9.0 -0.9  0.0   0  0.9  2.9  23.3   \n",
       "1         149          39   25  ...  0.0   8.5  0.0  0.0   0  0.2  2.1  20.4   \n",
       "2         185         102   96  ...  0.0   9.5 -2.4  0.0   0  0.3  3.4  12.3   \n",
       "3         179         143   28  ...  0.0  12.2 -2.2  0.0   0  0.4  2.6  34.6   \n",
       "4         177         103  -16  ...  0.0  13.1 -3.6  0.0   0 -0.1  3.9  25.4   \n",
       "\n",
       "     LG  diagnosis  \n",
       "0  49.4          8  \n",
       "1  38.8          6  \n",
       "2  49.0         10  \n",
       "3  61.6          1  \n",
       "4  62.8          7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  6, 10,  1,  7, 14,  3, 16,  2,  4,  5,  9, 15], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"diagnosis\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1356 entries, 0 to 1355\n",
      "Columns: 280 entries, Age to diagnosis\n",
      "dtypes: float64(121), int64(159)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>qrs_duration</th>\n",
       "      <th>p-r_interval</th>\n",
       "      <th>q-t_interval</th>\n",
       "      <th>t_interval</th>\n",
       "      <th>p_interval</th>\n",
       "      <th>qrs</th>\n",
       "      <th>...</th>\n",
       "      <th>KY</th>\n",
       "      <th>KZ</th>\n",
       "      <th>LA</th>\n",
       "      <th>LB</th>\n",
       "      <th>LC</th>\n",
       "      <th>LD</th>\n",
       "      <th>LE</th>\n",
       "      <th>LF</th>\n",
       "      <th>LG</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>1356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.471239</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>166.188053</td>\n",
       "      <td>68.170354</td>\n",
       "      <td>88.920354</td>\n",
       "      <td>155.152655</td>\n",
       "      <td>367.207965</td>\n",
       "      <td>169.949115</td>\n",
       "      <td>90.004425</td>\n",
       "      <td>33.676991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278982</td>\n",
       "      <td>9.048009</td>\n",
       "      <td>-1.457301</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>1.222345</td>\n",
       "      <td>19.326106</td>\n",
       "      <td>29.473230</td>\n",
       "      <td>3.880531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.454474</td>\n",
       "      <td>0.497587</td>\n",
       "      <td>37.142898</td>\n",
       "      <td>16.578554</td>\n",
       "      <td>15.353051</td>\n",
       "      <td>44.809176</td>\n",
       "      <td>33.360774</td>\n",
       "      <td>35.606765</td>\n",
       "      <td>25.807576</td>\n",
       "      <td>45.397893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548471</td>\n",
       "      <td>3.470298</td>\n",
       "      <td>2.000951</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347274</td>\n",
       "      <td>1.424999</td>\n",
       "      <td>13.493952</td>\n",
       "      <td>18.480273</td>\n",
       "      <td>4.403843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-44.200000</td>\n",
       "      <td>-38.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>25.825000</td>\n",
       "      <td>41.125000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>88.800000</td>\n",
       "      <td>115.900000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age          Sex       Height       Weight  qrs_duration  \\\n",
       "count  1356.000000  1356.000000  1356.000000  1356.000000   1356.000000   \n",
       "mean     46.471239     0.550885   166.188053    68.170354     88.920354   \n",
       "std      16.454474     0.497587    37.142898    16.578554     15.353051   \n",
       "min       0.000000     0.000000   105.000000     6.000000     55.000000   \n",
       "25%      36.000000     0.000000   160.000000    59.000000     80.000000   \n",
       "50%      47.000000     1.000000   164.000000    68.000000     86.000000   \n",
       "75%      58.000000     1.000000   170.000000    79.000000     94.000000   \n",
       "max      83.000000     1.000000   780.000000   176.000000    188.000000   \n",
       "\n",
       "       p-r_interval  q-t_interval   t_interval   p_interval          qrs  ...  \\\n",
       "count   1356.000000   1356.000000  1356.000000  1356.000000  1356.000000  ...   \n",
       "mean     155.152655    367.207965   169.949115    90.004425    33.676991  ...   \n",
       "std       44.809176     33.360774    35.606765    25.807576    45.397893  ...   \n",
       "min        0.000000    232.000000   108.000000     0.000000  -172.000000  ...   \n",
       "25%      142.000000    350.000000   148.000000    79.000000     3.750000  ...   \n",
       "50%      157.000000    367.000000   162.000000    91.000000    40.000000  ...   \n",
       "75%      175.000000    384.000000   179.000000   102.000000    66.000000  ...   \n",
       "max      524.000000    509.000000   381.000000   205.000000   169.000000  ...   \n",
       "\n",
       "                KY           KZ           LA           LB      LC  \\\n",
       "count  1356.000000  1356.000000  1356.000000  1356.000000  1356.0   \n",
       "mean     -0.278982     9.048009    -1.457301     0.003982     0.0   \n",
       "std       0.548471     3.470298     2.000951     0.050081     0.0   \n",
       "min      -4.100000     0.000000   -28.600000     0.000000     0.0   \n",
       "25%      -0.425000     6.600000    -2.100000     0.000000     0.0   \n",
       "50%       0.000000     8.800000    -1.100000     0.000000     0.0   \n",
       "75%       0.000000    11.200000     0.000000     0.000000     0.0   \n",
       "max       0.000000    23.600000     0.000000     0.800000     0.0   \n",
       "\n",
       "                LD           LE           LF           LG    diagnosis  \n",
       "count  1356.000000  1356.000000  1356.000000  1356.000000  1356.000000  \n",
       "mean      0.514823     1.222345    19.326106    29.473230     3.880531  \n",
       "std       0.347274     1.424999    13.493952    18.480273     4.403843  \n",
       "min      -0.800000    -6.000000   -44.200000   -38.600000     1.000000  \n",
       "25%       0.400000     0.500000    11.450000    17.550000     1.000000  \n",
       "50%       0.500000     1.350000    18.100000    27.900000     1.000000  \n",
       "75%       0.700000     2.100000    25.825000    41.125000     6.000000  \n",
       "max       2.400000     6.000000    88.800000   115.900000    16.000000  \n",
       "\n",
       "[8 rows x 280 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE PROCESSING DATA (Removing Missing & NaN values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1356 entries, 0 to 1355\n",
      "Columns: 280 entries, Age to diagnosis\n",
      "dtypes: float64(121), int64(159)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             0\n",
       "Sex             0\n",
       "Height          0\n",
       "Weight          0\n",
       "qrs_duration    0\n",
       "               ..\n",
       "LD              0\n",
       "LE              0\n",
       "LF              0\n",
       "LG              0\n",
       "diagnosis       0\n",
       "Length: 280, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Romes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "X=numpy.array(X)\n",
    "X=X.astype(numpy.float)\n",
    "\n",
    "y = data.iloc[:,-1]\n",
    "y=numpy.array(y)\n",
    "y=y.astype(numpy.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying random forests to get pricipal attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Romes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00498258 0.0070096  0.00586396 0.00546649 0.0097897  0.00698179\n",
      " 0.0078286  0.00496168 0.00839974 0.02081977 0.00597015 0.00572366\n",
      " 0.00485347 0.00612096 0.00524811 0.00567388 0.00502486 0.00526886\n",
      " 0.00550668 0.00536012 0.00814747 0.00531131 0.00469241 0.00750882\n",
      " 0.02243237 0.0236393  0.00717339 0.00492614 0.00779046 0.01407746\n",
      " 0.00506223 0.0125263  0.00894231 0.01090925 0.00634248 0.00600184\n",
      " 0.00532766 0.00569655 0.0056881  0.00459311 0.00531948 0.00461132\n",
      " 0.00559478 0.00478525 0.00518855 0.00515962 0.00467744 0.01067533\n",
      " 0.00568456 0.00505525 0.00557831 0.00755981 0.00491509 0.00569821\n",
      " 0.00921215 0.00619475 0.00500583 0.00887328 0.00454256 0.00630506\n",
      " 0.00468385 0.01202728 0.0086445  0.00569434 0.00627165 0.00453313\n",
      " 0.00720266 0.00455415 0.00571052 0.00544113 0.00680217 0.01516881\n",
      " 0.00686901 0.00561668 0.00869686 0.00526017 0.00533392 0.00481896\n",
      " 0.0061467  0.00742576 0.00481161 0.00606311 0.00553738 0.00497712\n",
      " 0.00682563 0.00600392 0.00583229 0.00663625 0.00631608 0.00551874\n",
      " 0.00687363 0.00728962 0.00689599 0.00464897 0.00497147 0.01139929\n",
      " 0.00796955 0.00605971 0.01258477 0.00453263 0.00480514 0.00656134\n",
      " 0.00456295 0.00495651 0.01265781 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "[  0   1   2   3   4   6   7   8  10  14  16  17  20  28  29  32  44  64\n",
      "  65  68  75  80  88  89  90  92  99 100 101 102 104 111 112 113 116 124\n",
      " 125 128 136 137 140 147 148 152 159 162 165 166 167 168 169 170 172 175\n",
      " 176 178 179 180 186 189 191 196 198 199 206 209 210 212 216 219 221 223\n",
      " 225 226 227 228 229 231 232 233 235 236 237 238 239 240 241 242 246 247\n",
      " 248 249 251 252 255 256 259 261 266 267 268 269 271 275 276   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "The no of features = 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75.    0.  190.  ...   9.    0.9   2.9]\n",
      " [ 56.    1.  165.  ...   8.5   0.2   2.1]\n",
      " [ 54.    0.  172.  ...   9.5   0.3   3.4]\n",
      " ...\n",
      " [ 36.    0.  166.  ...  16.3   1.5   1. ]\n",
      " [ 32.    1.  155.  ...  12.    0.5   2.4]\n",
      " [ 78.    1.  160.  ...  10.4   0.5   1.6]]\n"
     ]
    }
   ],
   "source": [
    "#applying random forests to get pricipal attributes\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y.ravel())\n",
    "#print(model.feature_importances_)\n",
    "\n",
    "numpy.savetxt(\"randforrests.csv\", model.feature_importances_, fmt='%s', delimiter=\",\")\n",
    "\n",
    "#selecting features \n",
    "c=0;\n",
    "important_features=numpy.zeros((278),dtype=numpy.float)\n",
    "important_features_index=numpy.zeros((278),dtype=numpy.int)\n",
    "\n",
    "for i in range (0,278):\n",
    "    if((model.feature_importances_[i]*1000)>=4.5):\n",
    "        important_features[c]=model.feature_importances_[i]\n",
    "        important_features_index[c]=i\n",
    "        c=c+1\n",
    "\n",
    "print(important_features)\n",
    "print(important_features_index)\n",
    "print(\"The no of features =\",c)\n",
    "\n",
    "#features are reduced  from 278\n",
    "\n",
    "numpy.savetxt(\"import_features_index_after_random_forrests.csv\",important_features_index, fmt='%s', delimiter=\",\")\n",
    "\n",
    "#new matrix compirising of reduced features\n",
    "newX=numpy.zeros((1356 ,c),dtype=numpy.float)\n",
    "for i in range (0,1356 ):\n",
    "    for j in range (0,c):\n",
    "        newX[i][j]=X[i][important_features_index[j]]\n",
    "\n",
    "\n",
    "print(newX)\n",
    "\n",
    "numpy.savetxt(\"reduced_features.csv\",newX, fmt='%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('reduced_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(x,y[:-1],test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "clf_KNN.fit(X_train,y_train)    ## fit ===> Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn  = clf_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867158671586716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred_knn,y_test))\n",
    "score_knn = accuracy_score(y_pred_knn,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_SVM = svm.SVC(C=1,kernel=\"linear\")\n",
    "clf_SVM.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm  = clf_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940959409594096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred_svm,y_test))\n",
    "score_svm = accuracy_score(y_pred_svm,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_LR = LogisticRegression(max_iter=100,C=1)\n",
    "clf_LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LR  = clf_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5571955719557196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred_LR,y_test))\n",
    "score_lr = accuracy_score(y_pred_LR,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navie Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_NB = clf_NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15867158671586715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred_NB,y_test))\n",
    "score_nb = accuracy_score(y_pred_NB,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weigth KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=13, weights='distance')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_WKNN = KNeighborsClassifier(n_neighbors=13,weights='distance')\n",
    "clf_WKNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_WKNN = clf_WKNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988929889298893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred_WKNN,y_test))\n",
    "score_wknn = accuracy_score(y_pred_WKNN,y_test)\n",
    "\n",
    "import pickle\n",
    "with open('wknn_check.pkl', 'wb') as file:\n",
    "   pickle.dump(clf_WKNN,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT= DecisionTreeClassifier()\n",
    "DT.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using KNN is: 0.5867158671586716 %\n",
      "The accuracy score achieved using Support Vector Machine is: 0.940959409594096 %\n",
      "The accuracy score achieved using Logistic regression is: 0.5571955719557196 %\n",
      "The accuracy score achieved using naviebayes is: 0.15867158671586715 %\n",
      "The accuracy score achieved using Weigthed - knn is: 0.988929889298893 %\n"
     ]
    }
   ],
   "source": [
    "scores = [score_knn,score_svm,score_lr,score_nb,score_wknn]\n",
    "algorithms = [\"KNN\",\"Support Vector Machine\",\"Logistic regression\",\"naviebayes\",\"Weigthed - knn\"]    \n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "barplot() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-6f88c9db3ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Algorithms\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: barplot() takes from 0 to 1 positional arguments but 2 were given"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "sns.barplot(x=algorithms,y=scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
